# Default values for caas kube-prometheus-stack.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

caas:
  rbac:
    # -- create a namespaces ServiceAccount
    enabled: true
    serviceAccount:
      create: true
      name: rancher-monitoring
  # deploy additional nginx.conf and dashboard for Grafana, mostly covered from Rancher
  # beware of the defaultDashboardsEnabled in kube-prometheus-stack
  grafana:
    configmaps: false
  fullnameOverride: ""
  nameOverride: ""
  # -- overrides the default namespace for caas related resources
  namespaceOverride: ""
  # -- whether the cluster has a dynatrace operator installed
  dynatrace: true
  # -- whether the cluster has kubecost installed
  clusterCosts: true
  # -- whether the cluster has Quality Dashboard  installed
  qualityDashboard: true
  # -- whether the cluster has Prometheus-Auth  installed
  prometheusAuth: true
  # -- whether the cluster needs defaultEgress  installed
  defaultEgress: false

global:
  cattle:
    clusterId: local
    clusterName: local
    # projectId: &projectId p-xxxxx
    systemDefaultRegistry: "mtr.devops.telekom.de"
  imageRegistry: mtr.devops.telekom.de

kube-prometheus-stack:
  #  full set of values and pre-defined for caas
  #  ref: https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml
  crds:
    enabled: false
  nameOverride: "rancher-monitoring"
  fullnameOverride: "rancher-monitoring"
  #commonLabels:
  #  field.cattle.io/projectId: *projectId

  ## Create default rules for monitoring the cluster
  ##
  defaultRules:
    create: true
    rules:
      alertmanager: true
      etcd: false
      configReloaders: true
      general: true
      k8s: true
      kubeApiserverAvailability: true
      kubeApiserverBurnrate: true
      kubeApiserverHistogram: true
      kubeApiserverSlos: true
      kubeControllerManager: true
      kubelet: true
      kubeProxy: true
      kubePrometheusGeneral: true
      kubePrometheusNodeRecording: true
      kubernetesApps: true
      kubernetesResources: true
      kubernetesStorage: true
      kubernetesSystem: true
      kubeScheduler: true
      kubeStateMetrics: true
      network: true
      node: true
      nodeExporterAlerting: true
      nodeExporterRecording: true
      prometheus: true
      prometheusOperator: true
    appNamespacesTarget: ".*"
    runbookUrl: "https://runbooks.prometheus-operator.dev/runbooks"
  ## Provide custom recording or alerting rules to be deployed into the cluster.
  ##
  alertmanager:
    apiVersion: v2
    enabled: true
    config:
      global:
        resolve_timeout: 5m
      inhibit_rules:
        - source_matchers:
            - "severity = critical"
          target_matchers:
            - "severity =~ warning|info"
          equal:
            - "namespace"
            - "alertname"
        - source_matchers:
            - "severity = warning"
          target_matchers:
            - "severity = info"
          equal:
            - "namespace"
            - "alertname"
        - source_matchers:
            - "alertname = InfoInhibitor"
          target_matchers:
            - "severity = info"
          equal:
            - "namespace"
      route:
        group_by: ["namespace"]
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 12h
        receiver: "null"
        routes:
          - receiver: "null"
            matchers:
              - alertname =~ "InfoInhibitor|Watchdog"
      receivers:
        - name: "null"
      templates:
        - "/etc/alertmanager/config/*.tmpl"
    serviceAccount:
      create: true
    service:
      annotations: {}
      labels: {}
      clusterIP: ""
      port: 9093
      targetPort: 9093
      externalIPs: []
      loadBalancerIP: ""
      loadBalancerSourceRanges: []
      externalTrafficPolicy: Cluster
      type: ClusterIP
    servicePerReplica:
      enabled: false
    serviceMonitor:
      interval: "30s"
      selfMonitor: true
    templateFiles:
      rancher_defaults.tmpl: >-
        {{- define "slack.rancher.text" -}}

        {{ template "rancher.text_multiple" . }}

        {{- end -}}

        {{- define "webex.text_multiple" -}}

        {{- range .Alerts }}

        {{ template "webex.text_single" . }}

        {{- end }}

        {{- if .ExternalURL }}

        AlertManager: <{{ .ExternalURL }}>
          
        {{- end }}

        {{- end -}}

        {{- define "webex.text_single" -}}

        {{- if .Labels.alertname }}

        ## [ALERT - {{ .Labels.alertname }}]

        {{- else }}

        ## [ALERT]

        {{- end }}

        {{- if .Labels.severity }}

        ### Severity: `{{ .Labels.severity }}`

        {{- end }}

        {{- if .Labels.cluster }}

        ### Cluster:  {{ .Labels.cluster }}

        {{- end }}

        {{- if .Annotations.summary }}

        ### Summary: {{ .Annotations.summary }}

        {{- end }}

        {{- if .Annotations.message }}

        Message:  {{ .Annotations.message }}

        {{- end }}

        {{- if .Annotations.description }}

        Description:  {{ .Annotations.description }}

        {{- end }}

        {{- if .Annotations.runbook_url }}

        Runbook URL: <{{ .Annotations.runbook_url }}|:spiral_note_pad:>

        {{- end }}

        {{- with .Labels }}

        {{- with .Remove (stringSlice "alertname" "severity" "cluster") }}

        {{- if gt (len .) 0 }}

        Additional Labels:
          {{- range .SortedPairs }}
          • {{ .Name }}: `{{ .Value }}`
          {{- end }}
        {{- end }}

        {{- end }}

        {{- end }}

        {{- with .Annotations }}

        {{- with .Remove (stringSlice "summary" "message" "description"
        "runbook_url") }}

        {{- if gt (len .) 0 }}

        ## Additional Annotations:*
          {{- range .SortedPairs }}
          • {{ .Name }}: `{{ .Value }}`
          {{- end }}
        {{- end }}

        {{- end }}

        {{- end }}


        {{- end -}}

        {{- define "rancher.text_multiple" -}}

        *[GROUP - Details]* 

        One or more alarms in this group have triggered a notification.


        {{- if gt (len .GroupLabels.Values) 0 }}

        *Group Labels:*
          {{- range .GroupLabels.SortedPairs }}
          • *{{ .Name }}:* `{{ .Value }}`
          {{- end }}
        {{- end }}

        {{- if .ExternalURL }}

        *Link to AlertManager:* {{ .ExternalURL }}

        {{- end }}


        {{- range .Alerts }}

        {{ template "rancher.text_single" . }}

        {{- end }}

        {{- end -}}


        {{- define "rancher.text_single" -}}

        {{- if .Labels.alertname }}

        *[ALERT - {{ .Labels.alertname }}]*

        {{- else }}

        *[ALERT]*

        {{- end }}

        {{- if .Labels.severity }}

        *Severity:* `{{ .Labels.severity }}`

        {{- end }}

        {{- if .Labels.cluster }}

        *Cluster:*  {{ .Labels.cluster }}

        {{- end }}

        {{- if .Annotations.summary }}

        *Summary:* {{ .Annotations.summary }}

        {{- end }}

        {{- if .Annotations.message }}

        *Message:* {{ .Annotations.message }}

        {{- end }}

        {{- if .Annotations.description }}

        *Description:* {{ .Annotations.description }}

        {{- end }}

        {{- if .Annotations.runbook_url }}

        *Runbook URL:* <{{ .Annotations.runbook_url }}|:spiral_note_pad:>

        {{- end }}

        {{- with .Labels }}

        {{- with .Remove (stringSlice "alertname" "severity" "cluster") }}

        {{- if gt (len .) 0 }}

        *Additional Labels:*
          {{- range .SortedPairs }}
          • *{{ .Name }}:* `{{ .Value }}`
          {{- end }}
        {{- end }}

        {{- end }}

        {{- end }}

        {{- with .Annotations }}

        {{- with .Remove (stringSlice "summary" "message" "description"
        "runbook_url") }}

        {{- if gt (len .) 0 }}

        *Additional Annotations:*
          {{- range .SortedPairs }}
          • *{{ .Name }}:* `{{ .Value }}`
          {{- end }}
        {{- end }}

        {{- end }}

        {{- end }}

        {{- end -}}
    alertmanagerSpec:
      alertmanagerConfigSelector:
        matchExpressions:
          - key: release
            operator: In
            values:
              - rancher-monitoring
      alertmanagerConfigNamespaceSelector: {}
      #alertmanagerConfigNamespaceSelector:
      #  matchLabels:
      #    "field.cattle.io/projectId": *projectId
      clusterAdvertiseAddress: false
      externalUrl:
      forceEnableClusterMode: false
      image:
        registry: mtr.devops.telekom.de
        repository: kubeprometheusstack/alertmanager
        tag: v0.26.0
      listenLocal: false
      logFormat: logfmt
      logLevel: info
      replicas: 1
      retention: 120h
      storage: {}
      # volumeClaimTemplate:
      #   spec:
      #     storageClassName: gluster
      #     accessModes: ["ReadWriteOnce"]
      #     resources:
      #       requests:
      #         storage: 50Gi
      #     selector: {}
      routePrefix: /
      resources:
        limits:
          memory: 750Mi
          cpu: 800m
        requests:
          memory: 200Mi
          cpu: 100m
      paused: false
      securityContext:
        fsGroup: 2000
        supplementalGroups:
          - 1000
      volumes: []
      volumeMounts: []
  global:
    rbac:
      create: true
      createAggregateClusterRoles: false
      pspEnabled: false
  grafana:
    adminPassword: prom-operator
    containerSecurityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
      privileged: false
      runAsUser: 472
      runAsGroup: 472
      readOnlyRootFilesystem: true
    createConfigmap: true
    datasources:
      datasources.yaml:
        apiVersion: 1
        datasources:
          - name: Prometheus
            type: prometheus
            url: http://prometheus-operated:9090
            access: proxy
            isDefault: true
    defaultDashboardsEnabled: true
    defaultDashboardsTimezone: utc
    enabled: true
    extraContainers: |
      - name: grafana-proxy
        args:
        - nginx
        - -g
        - daemon off;
        - -c
        - /nginx/nginx.conf
        image: mtr.devops.telekom.de/kubeprometheusstack/nginx:1.23.2-alpine
        ports:
        - containerPort: 8080
          name: nginx-http
          protocol: TCP
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
          requests:
            cpu: 50m
            memory: 50Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsUser: 101
          runAsGroup: 101
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /nginx
          name: grafana-nginx
        - mountPath: /var/cache/nginx
          name: nginx-home
    extraContainerVolumes:
      - name: nginx-home
        emptyDir: {}
      - name: grafana-nginx
        configMap:
          name: nginx-proxy-config-rancher-monitoring-grafana
          items:
            - key: nginx.conf
              mode: 438
              path: nginx.conf
    forceDeployDatasources: true
    forceDeployDashboards: true
    fullnameOverride: rancher-monitoring-grafana
    grafana.ini:
      analytics:
        check_for_updates: false
      users:
        auto_assign_org_role: Viewer
      auth:
        disable_login_form: false
      auth.anonymous:
        enabled: true
        org_role: Viewer
      auth.basic:
        enabled: false
      security:
        # Required to embed dashboards in Rancher Cluster Overview Dashboard on Cluster Explorer
        allow_embedding: true
      log:
        level: info
    image:
      repository: mtr.devops.telekom.de/kubeprometheusstack/grafana
      tag: 10.1.4
    initChownData:
      enabled: false
    namespaceOverride: ""
    nameOverride: rancher-monitoring-grafana
    rbac:
      create: false
      namespaced: true
      pspEnabled: false
    resources:
      limits:
        memory: 600Mi
        cpu: 600m
      requests:
        memory: 200Mi
        cpu: 200m
    serviceAccount:
      create: false
      name: rancher-monitoring
    securityContext:
      fsGroup: 472
      runAsUser: 472
      runAsGroup: 472
      supplementalGroups:
        - 472
    sidecar:
      image:
        repository: mtr.devops.telekom.de/kubeprometheusstack/k8s-sidecar
        tag: 1.24.6
      plugins:
        searchNamespace: ""
      resources:
        limits:
          cpu: 100m
          memory: 100Mi
        requests:
          cpu: 50m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
            - ALL
        readOnlyRootFilesystem: true
        runAsUser: 472
        runAsGroup: 472
        privileged: false
      dashboards:
        enabled: true
        label: grafana_dashboard
        labelValue: "1"
        annotations: {}
        multicluster:
          global:
            enabled: false
          etcd:
            enabled: false
        provider:
          allowUiUpdates: false
        searchNamespace: "cattle-monitoring-system"
      datasources:
        createPrometheusReplicasDatasources: false
        defaultDatasourceEnabled: false
        enabled: true
        label: grafana_datasource
        labelValue: "1"
        searchNamespace: ""
    serviceMonitor:
      enabled: true
      path: "/metrics"
      interval: "30s"
      scheme: http
      scrapeTimeout: 30s
    service:
      portName: nginx-http
      port: 80
      targetPort: 8080
    testFramework:
      enabled: false
  kubeApiServer:
    enabled: true
  kubelet:
    enabled: true
  kubeControllerManager:
    enabled: false
  coreDns:
    enabled: true
  kubeDns:
    enabled: false
  kubeEtcd:
    enabled: false
  kubeScheduler:
    enabled: false
  kubeProxy:
    enabled: false
  kubeStateMetrics:
    enabled: true
  kube-state-metrics:
    image:
      registry: mtr.devops.telekom.de
      repository: kubeprometheusstack/kube-state-metrics
      tag: v2.10.0
    rbac:
      create: true
    releaseLabel: false
    prometheus:
      monitor:
        enabled: true
        honorLabels: false
    selfMonitor:
      enabled: true
  nodeExporter:
    enabled: true
    operatingSystems:
      darwin:
        enabled: false
  prometheus-node-exporter:
    image:
      pullPolicy: Always
      registry: mtr.devops.telekom.de
      repository: kubeprometheusstack/node-exporter
    prometheus:
      monitor:
        enabled: true
    releaseLabel: true
    rbac:
      pspEnabled: false
    service:
      port: 9796
      targetPort: 9796
  prometheusOperator:
    admissionWebhooks:
      patch:
        image:
          pullPolicy: Always
          registry: mtr.devops.telekom.de
          repository: kubeprometheusstack/kube-webhook-certgen
          tag: v20221220-controller-v1.5.1-58-g787ea74b6
        resources:
          limits:
            cpu: 300m
            memory: 400Mi
          requests:
            cpu: 100m
            memory: 100Mi
        securityContext:
          runAsGroup: 2000
          runAsNonRoot: true
          runAsUser: 2000
          seccompProfile:
            type: RuntimeDefault
    image:
      pullPolicy: Always
      registry: mtr.devops.telekom.de
      repository: kubeprometheusstack/prometheus-operator
      tag: v0.68.0
    prometheusConfigReloader:
      image:
        registry: mtr.devops.telekom.de
        repository: kubeprometheusstack/prometheus-config-reloader
  prometheus:
    additionalRulesForClusterRole:
      - apiGroups:
          - ""
        resources:
          - configmaps
          - namespaces
          - nodes
          - nodes/metrics
          - services
          - endpoints
          - pods
          - secrets
        verbs:
          - get
          - list
          - watch
      - apiGroups:
          - networking.k8s.io
        resources:
          - ingresses
        verbs:
          - get
          - list
          - watch
      - nonResourceURLs:
          - /metrics
          - /metrics/cadvisor
        verbs:
          - get
      - apiGroups:
          - authentication.k8s.io
        resources:
          - tokenreviews
        verbs:
          - get
          - list
          - create
          - update
          - delete
          - watch
      - apiGroups:
          - authorization.k8s.io
        resources:
          - subjectaccessreviews
        verbs:
          - get
          - list
          - create
          - update
          - delete
          - watch
    enabled: true
    ingress:
      enabled: false
      annotations: {}
      labels: {}
      hosts: []
      paths: []
      tls: []
    ingressPerReplica:
      enabled: false
    prometheusSpec:
      additionalScrapeConfigs: []
      containers:
        - args:
            - --proxy-url=http://127.0.0.1:9090
            - --listen-address=$(POD_IP):9091
            - --filter-reader-labels=prometheus
            - --filter-reader-labels=prometheus_replica
            - --log.debug=true
          command:
            - prometheus-auth
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          image: mtr.devops.telekom.de/caas/prometheus-auth:0.5.1
          name: prometheus-agent
          ports:
            - containerPort: 9091
              name: http-auth
              protocol: TCP
          resources:
            limits:
              cpu: 500m
              memory: 500Mi
            requests:
              cpu: 100m
              memory: 500Mi
      disableCompaction: false
      enableAdminAPI: false
      evaluationInterval: "30s"
      externalLabels: {}
      externalUrl: ""
      excludedFromEnforcement: []
      enforcedNamespaceLabel: ""
      enforcedLabelLimit: false
      enforcedLabelNameLengthLimit: false
      enforcedLabelValueLengthLimit: false
      enforcedSampleLimit: false
      enforcedTargetLimit: false
      enableRemoteWriteReceiver: false
      image:
        registry: mtr.devops.telekom.de
        repository: kubeprometheusstack/prometheus
        tag: v2.46.0
      ignoreNamespaceSelectors: false
      listenLocal: false
      logFormat: logfmt
      logLevel: info
      overrideHonorLabels: false
      overrideHonorTimestamps: false
      portName: "http-web"
      prometheusRulesExcludedFromEnforce: []
      prometheusExternalLabelName: ""
      prometheusExternalLabelNameClear: false
      podAntiAffinityTopologyKey: kubernetes.io/hostname
      podMonitorSelector:
        matchExpressions:
          - key: release
            operator: In
            values:
              - rancher-monitoring
      podMonitorNamespaceSelector: {}
      #podMonitorNamespaceSelector:
      #  matchLabels:
      #    "field.cattle.io/projectId": *projectId
      #probeNamespaceSelector:
      #  matchLabels:
      #    "field.cattle.io/projectId": *projectId
      paused: false
      queryLogFile: false
      query: {}
      replicas: 1
      remoteRead: []
      remoteWrite: []
      remoteWriteDashboards: false
      resources:
        limits:
          memory: 4000Mi
          cpu: 2000m
        requests:
          memory: 400Mi
          cpu: 400m
      retention: 10d
      #retentionSize: ""
      routePrefix: /
      replicaExternalLabelName: ""
      replicaExternalLabelNameClear: false
      ruleNamespaceSelector: {}
      #ruleNamespaceSelector:
      #  matchLabels:
      #    "field.cattle.io/projectId": *projectId
      ruleSelector:
        matchExpressions:
          - key: release
            operator: In
            values:
              - rancher-monitoring
      scrapeInterval: "30s"
      scrapeTimeout: "10s"
      securityContext:
        fsGroup: 2000
        supplementalGroups:
          - 1000
      serviceMonitorSelector:
        matchExpressions:
          - key: release
            operator: In
            values:
              - rancher-monitoring
      serviceMonitorNamespaceSelector: {}
      #serviceMonitorNamespaceSelector:
      #  matchLabels:
      #    "field.cattle.io/projectId": *projectId
      shards: 1
      storageSpec: {}
      ## Using PersistentVolumeClaim
      ##
      #  volumeClaimTemplate:
      #    spec:
      #      storageClassName: gluster
      #      accessModes: ["ReadWriteOnce"]
      #      resources:
      #        requests:
      #          storage: 50Gi
      #    selector: {}
      ## Using tmpfs volume
      ##
      #  emptyDir:
      #    medium: Memory
      tsdb:
        outOfOrderTimeWindow: 0s
      volumes: []
      volumeMounts: []
      walCompression: true
    serviceAccount:
      create: true
      name: rancher-monitoring
    service:
      additionalPorts:
        - name: http-auth
          port: 9091
          protocol: TCP
          targetPort: http-auth
      annotations: {}
      clusterIP: ""
      externalIPs: []
      externalTrafficPolicy: Cluster
      labels: {}
      port: 9090
      publishNotReadyAddresses: false
      targetPort: 9090
      type: ClusterIP
    servicePerReplica:
      enabled: false
    serviceMonitor:
      interval: "30s"
      selfMonitor: true
      scheme: ""
      tlsConfig: {}
      bearerTokenFile:
      metricRelabelings: []
      relabelings: []
  thanosRuler:
    enabled: false
# refer to Rancher specific things,holding as sub charts in https://github.com/rancher/charts/tree/release-v2.7/charts/rancher-monitoring/102.0.2%2Bup40.1.2/charts
# try to adapt from kps components, or copy the sub chart content here
k3sServer:
  enabled: false
  metricsPort: 10250
  component: k3s-server
  clients:
    port: 10013
    useLocalhost: true
    https:
      enabled: true
      useServiceAccountCredentials: true
      insecureSkipVerify: true
    rbac:
      additionalRules:
        - nonResourceURLs: ["/metrics/cadvisor"]
          verbs: ["get"]
        - apiGroups: [""]
          resources: ["nodes/metrics"]
          verbs: ["get"]
    tolerations:
      - effect: "NoExecute"
        operator: "Exists"
      - effect: "NoSchedule"
        operator: "Exists"
  serviceMonitor:
    endpoints:
      - port: metrics
        honorLabels: true
        relabelings:
          - sourceLabels: [__metrics_path__]
            targetLabel: metrics_path
      - port: metrics
        path: /metrics/cadvisor
        honorLabels: true
        relabelings:
          - sourceLabels: [__metrics_path__]
            targetLabel: metrics_path
      - port: metrics
        path: /metrics/probes
        honorLabels: true
        relabelings:
          - sourceLabels: [__metrics_path__]
            targetLabel: metrics_path

rkeControllerManager:
  enabled: false
  metricsPort: 10257 # default to secure port as of k8s >= 1.22
  component: kube-controller-manager
  clients:
    https:
      enabled: true
      insecureSkipVerify: true
      useServiceAccountCredentials: true
    port: 10011
    useLocalhost: true
    nodeSelector:
      node-role.kubernetes.io/controlplane: "true"
    tolerations:
      - effect: "NoExecute"
        operator: "Exists"
      - effect: "NoSchedule"
        operator: "Exists"
  kubeVersionOverrides:
    - constraint: "< 1.22"
      values:
        metricsPort: 10252 # default to insecure port in k8s < 1.22
        clients:
          https:
            enabled: false
            insecureSkipVerify: false
            useServiceAccountCredentials: false

rkeScheduler:
  enabled: false
  metricsPort: 10259
  component: kube-scheduler
  clients:
    https:
      enabled: true
      insecureSkipVerify: true
      useServiceAccountCredentials: true
    port: 10012
    useLocalhost: true
    nodeSelector:
      node-role.kubernetes.io/controlplane: "true"
    tolerations:
      - effect: "NoExecute"
        operator: "Exists"
      - effect: "NoSchedule"
        operator: "Exists"
  kubeVersionOverrides:
    - constraint: "< 1.23"
      values:
        metricsPort: 10251 # default to insecure port in k8s < 1.23
        clients:
          https:
            enabled: false
            insecureSkipVerify: false
            useServiceAccountCredentials: false

rkeProxy:
  enabled: false
  metricsPort: 10249
  component: kube-proxy
  clients:
    port: 10013
    useLocalhost: true
    tolerations:
      - effect: "NoExecute"
        operator: "Exists"
      - effect: "NoSchedule"
        operator: "Exists"

rkeEtcd:
  enabled: false
  metricsPort: 2379
  component: kube-etcd
  clients:
    port: 10014
    https:
      enabled: true
      certDir: /etc/kubernetes/ssl
      certFile: kube-etcd-*.pem
      keyFile: kube-etcd-*-key.pem
      caCertFile: kube-ca.pem
      seLinuxOptions:
        # Gives rkeEtcd permissions to read files in /etc/kubernetes/*
        # Type is defined in https://github.com/rancher/rancher-selinux
        type: rke_kubereader_t
    nodeSelector:
      node-role.kubernetes.io/etcd: "true"
    tolerations:
      - effect: "NoExecute"
        operator: "Exists"
      - effect: "NoSchedule"
        operator: "Exists"

rkeIngressNginx:
  enabled: false
  metricsPort: 10254
  component: ingress-nginx
  clients:
    port: 10015
    useLocalhost: true
    tolerations:
      - effect: "NoExecute"
        operator: "Exists"
      - effect: "NoSchedule"
        operator: "Exists"
    nodeSelector:
      node-role.kubernetes.io/worker: "true"
